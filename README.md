# üß† Cognitive Agent

Cognitive Agent is an intelligent web application that transforms static documents and web pages into interactive conversational partners. Upload a PDF or provide a URL, and the application will ingest, summarize, and prepare the content, allowing you to ask questions and get precise answers directly from the source material.

![Cognitive Agent Screenshot](https://drive.google.com/file/d/19AmolhbVsfZctNXSI9gc94ZRxPYJww4E/view?usp=drive_link)
*(It's highly recommended to replace the link above with a real screenshot or GIF of your application in action!)*

---

## üìã Table of Contents

* [How It Works](#-how-it-works)
* [Tech Stack](#-tech-stack)
* [Getting Started](#-getting-started)
* [Usage](#-usage)
* [Contributing](#-contributing)
* [License](#-license)

---

## ‚ú® How It Works

This application uses a multi-agent system to process, understand, and converse with your documents. Below is a breakdown of the core features and the technology that powers them.

* **Multi-Source Ingestion:** The FastAPI backend exposes an endpoint that accepts both file uploads (`UploadFile`) and URL strings (`Form`). If a file is provided, its bytes are read directly. If a URL is provided, the `scrape_website_text` function uses the `requests` and `BeautifulSoup` libraries to fetch and parse the HTML content, extracting clean text.

* **Hybrid PDF Processing:** When a PDF is uploaded, the `read_pdf_file` function first attempts to extract text directly using `PyMuPDF`. It iterates through each page; if a page yields no text (a sign of a scanned image), it automatically falls back to an OCR pipeline. The page is rendered as a high-DPI image, which is then processed by `Pytesseract` to recognize and extract the text.

* **AI-Powered Summarization:** The full, extracted text is passed to the `run_summarizer_agent`. This agent takes large documents, breaks them into manageable chunks, and sends each chunk to the Google Gemini model with a prompt to summarize it. Finally, a concluding prompt asks the model to synthesize these partial summaries into a single, cohesive final summary.

* **Interactive Chat:** The React frontend manages a chat history state. When you send a message, it makes a POST request to the `/chat/` endpoint. The `answer_question_orchestrator` on the backend receives the question, the chat history, and the session's context. It first attempts to answer using only the summary.

* **Retrieval-Augmented Generation (RAG):** If the initial attempt to answer from the summary fails, the orchestrator escalates to the `run_rag_pipeline`. This function takes your question and uses a FAISS vector store (created when the document was first processed) to find the most semantically similar text chunks from the original document. These chunks and your question are then sent to the Gemini model with a prompt instructing it to answer based *only* on the provided context, ensuring factual, grounded responses.

* **Smart Question Suggestions:** After the initial summary is generated, the `run_question_suggester_agent` is called. It sends the summary to the Gemini model with a prompt asking it to generate three relevant, insightful follow-up questions a user might have. These are then displayed on the frontend to help start the conversation.

* **Engaging User Experience:** The React application closely monitors the processing status. When a document is submitted, the frontend polls a `/status/{session_id}` endpoint. The backend updates the status with progress messages like "Summarizing content‚Ä¶" or "Building vector index‚Ä¶". The frontend displays these messages in real-time. If the initial upload takes more than 20 seconds (a sign of slow OCR), a riddle component is displayed to keep the user engaged.

---

## üõ†Ô∏è Tech Stack

* **Backend:**
    * Python 3.x
    * FastAPI (for the web server)
    * LangChain (for the AI pipeline)
    * Google Generative AI (for LLM and embeddings)
    * FAISS (for vector storage)
    * PyMuPDF, Pytesseract & Pillow (for PDF/OCR processing)
    * BeautifulSoup4 (for web scraping)
* **Frontend:**
    * React (with TypeScript)
    * TailwindCSS (for styling)
    * Lucide React (for icons)

---

## üöÄ Getting Started

Follow these instructions to set up and run the project on your local machine.

### Prerequisites

1.  **Python & Node.js:** Ensure you have Python 3.8+ and Node.js v18+ installed.
2.  **Tesseract OCR:** This is required for processing scanned PDFs.
    * Download and install it from the [official Tesseract documentation](https://tesseract-ocr.github.io/tessdoc/Installation.html).
    * **Crucially, ensure you add Tesseract to your system's PATH during installation.**
3.  **Google API Key:**
    * You need a Google Generative AI API key. You can get one from [Google AI Studio](https://aistudio.google.com/app/apikey).

### Backend Setup

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/your-repo-name.git](https://github.com/your-username/your-repo-name.git)
    cd your-repo-name
    ```

2.  **Create a virtual environment and install dependencies:**
    ```bash
    # Create a virtual environment
    python -m venv venv

    # Activate it (Windows)
    .\venv\Scripts\activate

    # Activate it (macOS/Linux)
    source venv/bin/activate

    # Install Python packages
    pip install -r requirements.txt
    ```
    *(Note: You will need to create a `requirements.txt` file. You can generate one from your activated virtual environment using `pip freeze > requirements.txt`)*

3.  **Create a `.env` file** in the root project directory and add your API key:
    ```
    GOOGLE_API_KEY="your_google_api_key_here"
    ```

### Frontend Setup

1.  **Navigate to the frontend directory** (assuming your React app is in a subfolder like `frontend/`):
    ```bash
    cd frontend/
    ```

2.  **Install npm packages:**
    ```bash
    npm install
    ```

---

## ‚ñ∂Ô∏è Usage

1.  **Start the Backend Server:**
    In a terminal, from the root directory (with your virtual environment activated), run the FastAPI application:
    ```bash
    uvicorn api:app --reload
    ```
    The backend will now be running at `http://127.0.0.1:8000`.

2.  **Start the Frontend Application:**
    In a **separate terminal**, from the `frontend/` directory, run the React development server:
    ```bash
    npm start
    ```
    The application will open in your browser, usually at `http://localhost:3000`.

3.  Upload a document or paste a URL to begin!

---

## ü§ù Contributing

Contributions are welcome! If you'd like to help improve Cognitive Agent, please follow these steps:

1.  Fork the repository.
2.  Create a new branch (`git checkout -b feature/your-feature-name`).
3.  Make your changes.
4.  Commit your changes (`git commit -m 'Add some amazing feature'`).
5.  Push to the branch (`git push origin feature/your-feature-name`).
6.  Open a Pull Request.

---

## üìú License

This project is licensed under the MIT License. See the `LICENSE` file for details.
